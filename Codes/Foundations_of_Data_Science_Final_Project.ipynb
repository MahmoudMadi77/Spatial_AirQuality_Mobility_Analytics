{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTVbZpKdu2v7",
        "outputId": "ece2c807-6759-4ec5-cfcb-5b7a69c7cf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: geohash2 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (1.1)\n",
            "Requirement already satisfied: geopandas in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (1.0.1)\n",
            "Requirement already satisfied: datascience in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (0.17.6)\n",
            "Requirement already satisfied: shapely in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (2.2.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (3.10.1)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
            "     --------------------------------------- 11.1/11.1 MB 19.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: docutils>=0.3 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from geohash2) (0.21.2)\n",
            "Requirement already satisfied: numpy>=1.22 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from geopandas) (24.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: folium>=0.9.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from datascience) (0.16.0)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from datascience) (65.5.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from datascience) (1.15.2)\n",
            "Requirement already satisfied: ipython in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from datascience) (9.1.0)\n",
            "Requirement already satisfied: plotly in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from datascience) (6.0.1)\n",
            "Requirement already satisfied: branca in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from datascience) (0.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.3)\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "     -------------------------------------- 301.8/301.8 kB 4.7 MB/s eta 0:00:00\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: jinja2>=2.9 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from folium>=0.9.1->datascience) (3.1.3)\n",
            "Requirement already satisfied: requests in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from folium>=0.9.1->datascience) (2.31.0)\n",
            "Requirement already satisfied: xyzservices in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from folium>=0.9.1->datascience) (2024.4.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from pyogrio>=0.7.2->geopandas) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (2.18.0)\n",
            "Requirement already satisfied: stack_data in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (5.14.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from ipython->datascience) (4.13.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from plotly->datascience) (1.36.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython->datascience) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium>=0.9.1->datascience) (2.1.5)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->datascience) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium>=0.9.1->datascience) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium>=0.9.1->datascience) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium>=0.9.1->datascience) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython->datascience) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython->datascience) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\abdullah\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython->datascience) (0.2.3)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn, seaborn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 seaborn-0.13.2 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install any required packages (Colab only)\n",
        "#!pip install geohash2 geopandas datascience shapely pandas matplotlib seaborn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1bIvSO5cqsOF"
      },
      "outputs": [],
      "source": [
        "# Traffic & Air Quality Analysis Using datascience + GeoPandas + DBSCAN + Geohashing\n",
        "\n",
        "# STEP 1: Import libraries\n",
        "# ----------------------------------------\n",
        "# Import all necessary libraries for data handling, spatial analysis, plotting, and clustering\n",
        "from datascience import Table\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import geohash2\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zCGr-UsKq_Dv",
        "outputId": "1c7adb91-4f52-413a-c456-cbf8750a97d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Latitude', 'Longitude', 'ReadingDateTimeUTC', 'PM25', 'CalibratedPM25',\n",
            "       'CalibratedO3', 'CalibratedNO2', 'CO'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# STEP 2: Load and combine AIR QUALITY data from multiple CSVs\n",
        "# ----------------------------------------\n",
        "# Combine all air quality data parts into one DataFrame\n",
        "files = sorted(glob.glob(\"chicago_eclipse_data_part_*.csv\"))\n",
        "aq_df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
        "aq_df = aq_df.drop(columns=[\n",
        "    \"City\",\n",
        "    \"DeviceId\",\n",
        "    \"LocationName\",\n",
        "    \"Temperature\",\n",
        "    \"Humidity\",\n",
        "    \"BatteryLevel\",\n",
        "    \"PercentBattery\",\n",
        "    \"CellSignal\"\n",
        "])\n",
        "print(aq_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>ReadingDateTimeUTC</th>\n",
              "      <th>PM25</th>\n",
              "      <th>CalibratedPM25</th>\n",
              "      <th>CalibratedO3</th>\n",
              "      <th>CalibratedNO2</th>\n",
              "      <th>CO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41.794921</td>\n",
              "      <td>-87.625857</td>\n",
              "      <td>2021-06-20 00:03:00+00:00</td>\n",
              "      <td>5.561094</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.123580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.794921</td>\n",
              "      <td>-87.625857</td>\n",
              "      <td>2021-06-20 00:08:10+00:00</td>\n",
              "      <td>6.633914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.132103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41.794921</td>\n",
              "      <td>-87.625857</td>\n",
              "      <td>2021-06-20 00:13:20+00:00</td>\n",
              "      <td>4.068707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.131126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.794921</td>\n",
              "      <td>-87.625857</td>\n",
              "      <td>2021-06-20 00:18:30+00:00</td>\n",
              "      <td>6.351702</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.138784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.794921</td>\n",
              "      <td>-87.625857</td>\n",
              "      <td>2021-06-20 00:23:40+00:00</td>\n",
              "      <td>9.574065</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.413070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461084</th>\n",
              "      <td>41.903627</td>\n",
              "      <td>-87.643443</td>\n",
              "      <td>2021-08-20 11:55:10+00:00</td>\n",
              "      <td>17.235613</td>\n",
              "      <td>15.85</td>\n",
              "      <td>22.52</td>\n",
              "      <td>13.78</td>\n",
              "      <td>0.407807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461085</th>\n",
              "      <td>41.903627</td>\n",
              "      <td>-87.643443</td>\n",
              "      <td>2021-08-20 12:00:20+00:00</td>\n",
              "      <td>11.742577</td>\n",
              "      <td>14.20</td>\n",
              "      <td>20.00</td>\n",
              "      <td>12.48</td>\n",
              "      <td>0.382384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461086</th>\n",
              "      <td>41.903627</td>\n",
              "      <td>-87.643443</td>\n",
              "      <td>2021-08-20 12:05:30+00:00</td>\n",
              "      <td>13.482563</td>\n",
              "      <td>14.78</td>\n",
              "      <td>21.90</td>\n",
              "      <td>13.01</td>\n",
              "      <td>0.385963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461087</th>\n",
              "      <td>41.903627</td>\n",
              "      <td>-87.643443</td>\n",
              "      <td>2021-08-20 12:10:39+00:00</td>\n",
              "      <td>10.450826</td>\n",
              "      <td>15.47</td>\n",
              "      <td>19.72</td>\n",
              "      <td>13.55</td>\n",
              "      <td>0.438555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461088</th>\n",
              "      <td>41.903627</td>\n",
              "      <td>-87.643443</td>\n",
              "      <td>2021-08-20 12:15:50+00:00</td>\n",
              "      <td>18.644289</td>\n",
              "      <td>16.31</td>\n",
              "      <td>24.55</td>\n",
              "      <td>13.50</td>\n",
              "      <td>0.416905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2461089 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Latitude  Longitude        ReadingDateTimeUTC       PM25  \\\n",
              "0        41.794921 -87.625857 2021-06-20 00:03:00+00:00   5.561094   \n",
              "1        41.794921 -87.625857 2021-06-20 00:08:10+00:00   6.633914   \n",
              "2        41.794921 -87.625857 2021-06-20 00:13:20+00:00   4.068707   \n",
              "3        41.794921 -87.625857 2021-06-20 00:18:30+00:00   6.351702   \n",
              "4        41.794921 -87.625857 2021-06-20 00:23:40+00:00   9.574065   \n",
              "...            ...        ...                       ...        ...   \n",
              "2461084  41.903627 -87.643443 2021-08-20 11:55:10+00:00  17.235613   \n",
              "2461085  41.903627 -87.643443 2021-08-20 12:00:20+00:00  11.742577   \n",
              "2461086  41.903627 -87.643443 2021-08-20 12:05:30+00:00  13.482563   \n",
              "2461087  41.903627 -87.643443 2021-08-20 12:10:39+00:00  10.450826   \n",
              "2461088  41.903627 -87.643443 2021-08-20 12:15:50+00:00  18.644289   \n",
              "\n",
              "         CalibratedPM25  CalibratedO3  CalibratedNO2        CO  \n",
              "0                   NaN           NaN            NaN  0.123580  \n",
              "1                   NaN           NaN            NaN  0.132103  \n",
              "2                   NaN           NaN            NaN  0.131126  \n",
              "3                   NaN           NaN            NaN  0.138784  \n",
              "4                   NaN           NaN            NaN  0.413070  \n",
              "...                 ...           ...            ...       ...  \n",
              "2461084           15.85         22.52          13.78  0.407807  \n",
              "2461085           14.20         20.00          12.48  0.382384  \n",
              "2461086           14.78         21.90          13.01  0.385963  \n",
              "2461087           15.47         19.72          13.55  0.438555  \n",
              "2461088           16.31         24.55          13.50  0.416905  \n",
              "\n",
              "[2461089 rows x 8 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aq_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FS7E3IDTrDCC"
      },
      "outputs": [],
      "source": [
        "# Convert timestamp to datetime format\n",
        "aq_df[\"ReadingDateTimeUTC\"] = pd.to_datetime(aq_df[\"ReadingDateTimeUTC\"], utc=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ziONSOhXrFAk"
      },
      "outputs": [],
      "source": [
        "# Create geometry column for air quality sensor locations\n",
        "aq_df[\"geometry\"] = aq_df.apply(lambda row: Point(row[\"Longitude\"], row[\"Latitude\"]), axis=1)\n",
        "gdf_aq = gpd.GeoDataFrame(aq_df, geometry=\"geometry\", crs=\"EPSG:4326\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "S6vvIs1CrJBv",
        "outputId": "d69a727f-e4ef-4f46-8e0d-690490c325d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Trip Start Timestamp', 'Trip End Timestamp', 'Trip Seconds',\n",
            "       'Trip Miles', 'Pickup Centroid Latitude', 'Pickup Centroid Longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# STEP 3: Load TAXI data\n",
        "# ----------------------------------------\n",
        "# Load taxi trip data from a single file\n",
        "taxi_df = pd.read_csv(\"taxi_data.csv\")\n",
        "\n",
        "# Keep only relevant columns\n",
        "columns_to_keep = [\n",
        "    \"Trip Start Timestamp\",\n",
        "    \"Trip End Timestamp\",\n",
        "    \"Trip Seconds\",\n",
        "    \"Trip Miles\",\n",
        "    \"Pickup Centroid Latitude\",\n",
        "    \"Pickup Centroid Longitude\"\n",
        "]\n",
        "\n",
        "taxi_df = taxi_df[columns_to_keep]\n",
        "\n",
        "print(taxi_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trip Start Timestamp</th>\n",
              "      <th>Trip End Timestamp</th>\n",
              "      <th>Trip Seconds</th>\n",
              "      <th>Trip Miles</th>\n",
              "      <th>Pickup Centroid Latitude</th>\n",
              "      <th>Pickup Centroid Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>10/03/2021 09:00:00 PM</td>\n",
              "      <td>1584.0</td>\n",
              "      <td>18.07</td>\n",
              "      <td>41.877406</td>\n",
              "      <td>-87.621972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>10/03/2021 09:00:00 PM</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>41.979071</td>\n",
              "      <td>-87.903040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>10/03/2021 08:45:00 PM</td>\n",
              "      <td>660.0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>41.899602</td>\n",
              "      <td>-87.633308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>498.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>41.980264</td>\n",
              "      <td>-87.913625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/03/2021 08:30:00 PM</td>\n",
              "      <td>10/03/2021 08:45:00 PM</td>\n",
              "      <td>618.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>41.878866</td>\n",
              "      <td>-87.625192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618446</th>\n",
              "      <td>01/01/2021 08:45:00 PM</td>\n",
              "      <td>01/01/2021 09:15:00 PM</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>41.707311</td>\n",
              "      <td>-87.534903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618447</th>\n",
              "      <td>01/01/2021 08:45:00 PM</td>\n",
              "      <td>01/01/2021 09:00:00 PM</td>\n",
              "      <td>807.0</td>\n",
              "      <td>4.21</td>\n",
              "      <td>41.953582</td>\n",
              "      <td>-87.723452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618448</th>\n",
              "      <td>01/01/2021 08:45:00 PM</td>\n",
              "      <td>01/01/2021 09:00:00 PM</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>41.792592</td>\n",
              "      <td>-87.769615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618449</th>\n",
              "      <td>01/01/2021 08:45:00 PM</td>\n",
              "      <td>01/01/2021 09:15:00 PM</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>8.90</td>\n",
              "      <td>41.835118</td>\n",
              "      <td>-87.618678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618450</th>\n",
              "      <td>01/01/2021 08:45:00 PM</td>\n",
              "      <td>01/01/2021 09:15:00 PM</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>15.83</td>\n",
              "      <td>41.899602</td>\n",
              "      <td>-87.633308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2618451 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Trip Start Timestamp      Trip End Timestamp  Trip Seconds  \\\n",
              "0        10/03/2021 08:30:00 PM  10/03/2021 09:00:00 PM        1584.0   \n",
              "1        10/03/2021 08:30:00 PM  10/03/2021 09:00:00 PM        1606.0   \n",
              "2        10/03/2021 08:30:00 PM  10/03/2021 08:45:00 PM         660.0   \n",
              "3        10/03/2021 08:30:00 PM  10/03/2021 08:30:00 PM         498.0   \n",
              "4        10/03/2021 08:30:00 PM  10/03/2021 08:45:00 PM         618.0   \n",
              "...                         ...                     ...           ...   \n",
              "2618446  01/01/2021 08:45:00 PM  01/01/2021 09:15:00 PM        1500.0   \n",
              "2618447  01/01/2021 08:45:00 PM  01/01/2021 09:00:00 PM         807.0   \n",
              "2618448  01/01/2021 08:45:00 PM  01/01/2021 09:00:00 PM        1260.0   \n",
              "2618449  01/01/2021 08:45:00 PM  01/01/2021 09:15:00 PM        1320.0   \n",
              "2618450  01/01/2021 08:45:00 PM  01/01/2021 09:15:00 PM        1320.0   \n",
              "\n",
              "         Trip Miles  Pickup Centroid Latitude  Pickup Centroid Longitude  \n",
              "0             18.07                 41.877406                 -87.621972  \n",
              "1             16.60                 41.979071                 -87.903040  \n",
              "2              1.40                 41.899602                 -87.633308  \n",
              "3              3.45                 41.980264                 -87.913625  \n",
              "4              0.00                 41.878866                 -87.625192  \n",
              "...             ...                       ...                        ...  \n",
              "2618446       11.90                 41.707311                 -87.534903  \n",
              "2618447        4.21                 41.953582                 -87.723452  \n",
              "2618448        0.00                 41.792592                 -87.769615  \n",
              "2618449        8.90                 41.835118                 -87.618678  \n",
              "2618450       15.83                 41.899602                 -87.633308  \n",
              "\n",
              "[2618451 rows x 6 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "taxi_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Null values in Air Quality Data:\n",
            "Latitude              0\n",
            "Longitude             0\n",
            "ReadingDateTimeUTC    0\n",
            "PM25                  0\n",
            "CalibratedPM25        0\n",
            "CalibratedO3          0\n",
            "CalibratedNO2         0\n",
            "CO                    0\n",
            "geometry              0\n",
            "dtype: int64\n",
            "🔍 Null values in Taxi Data:\n",
            "Trip Start Timestamp         0\n",
            "Trip End Timestamp           0\n",
            "Trip Seconds                 0\n",
            "Trip Miles                   0\n",
            "Pickup Centroid Latitude     0\n",
            "Pickup Centroid Longitude    0\n",
            "dtype: int64\n",
            "🧾 Missing values in Air Quality Data:\n",
            "Empty DataFrame\n",
            "Columns: [Null Count, Percent]\n",
            "Index: []\n",
            "\n",
            "🧾 Missing values in Taxi Data:\n",
            "Empty DataFrame\n",
            "Columns: [Null Count, Percent]\n",
            "Index: []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"🔍 Null values in Air Quality Data:\")\n",
        "print(aq_df.isnull().sum())\n",
        "\n",
        "print(\"🔍 Null values in Taxi Data:\")\n",
        "print(taxi_df.isnull().sum())\n",
        "\n",
        "def null_report(df, name):\n",
        "    print(f\"🧾 Missing values in {name}:\")\n",
        "    nulls = df.isnull().sum()\n",
        "    percent = (nulls / len(df)) * 100\n",
        "    report = pd.DataFrame({\"Null Count\": nulls, \"Percent\": percent.round(2)})\n",
        "    print(report[report[\"Null Count\"] > 0])  # Show only columns with nulls\n",
        "    print()\n",
        "\n",
        "null_report(aq_df, \"Air Quality Data\")\n",
        "null_report(taxi_df, \"Taxi Data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop all rows with any NaN values in air quality data\n",
        "aq_df = aq_df.dropna()\n",
        "# Drop all rows with any NaN values in taxi data\n",
        "taxi_df = taxi_df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZI77gj_oyzPh"
      },
      "outputs": [],
      "source": [
        "taxi_df = taxi_df.copy()\n",
        "# Convert pickup and dropoff timestamps to datetime format\n",
        "taxi_df[\"Trip Start Timestamp\"] = pd.to_datetime(\n",
        "    taxi_df[\"Trip Start Timestamp\"],\n",
        "    format=\"%m/%d/%Y  %I:%M:%S %p\",\n",
        "    utc=True\n",
        ")\n",
        "taxi_df[\"Trip End Timestamp\"] = pd.to_datetime(\n",
        "    taxi_df[\"Trip End Timestamp\"],\n",
        "    format=\"%m/%d/%Y  %I:%M:%S %p\",\n",
        "    utc=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trip Start Timestamp</th>\n",
              "      <th>Trip End Timestamp</th>\n",
              "      <th>Trip Seconds</th>\n",
              "      <th>Trip Miles</th>\n",
              "      <th>Pickup Centroid Latitude</th>\n",
              "      <th>Pickup Centroid Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>2021-10-03 21:00:00+00:00</td>\n",
              "      <td>1584.0</td>\n",
              "      <td>18.07</td>\n",
              "      <td>41.877406</td>\n",
              "      <td>-87.621972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>2021-10-03 21:00:00+00:00</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>41.979071</td>\n",
              "      <td>-87.903040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>2021-10-03 20:45:00+00:00</td>\n",
              "      <td>660.0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>41.899602</td>\n",
              "      <td>-87.633308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>498.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>41.980264</td>\n",
              "      <td>-87.913625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-10-03 20:30:00+00:00</td>\n",
              "      <td>2021-10-03 20:45:00+00:00</td>\n",
              "      <td>618.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>41.878866</td>\n",
              "      <td>-87.625192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618446</th>\n",
              "      <td>2021-01-01 20:45:00+00:00</td>\n",
              "      <td>2021-01-01 21:15:00+00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>41.707311</td>\n",
              "      <td>-87.534903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618447</th>\n",
              "      <td>2021-01-01 20:45:00+00:00</td>\n",
              "      <td>2021-01-01 21:00:00+00:00</td>\n",
              "      <td>807.0</td>\n",
              "      <td>4.21</td>\n",
              "      <td>41.953582</td>\n",
              "      <td>-87.723452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618448</th>\n",
              "      <td>2021-01-01 20:45:00+00:00</td>\n",
              "      <td>2021-01-01 21:00:00+00:00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>41.792592</td>\n",
              "      <td>-87.769615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618449</th>\n",
              "      <td>2021-01-01 20:45:00+00:00</td>\n",
              "      <td>2021-01-01 21:15:00+00:00</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>8.90</td>\n",
              "      <td>41.835118</td>\n",
              "      <td>-87.618678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618450</th>\n",
              "      <td>2021-01-01 20:45:00+00:00</td>\n",
              "      <td>2021-01-01 21:15:00+00:00</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>15.83</td>\n",
              "      <td>41.899602</td>\n",
              "      <td>-87.633308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2410356 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Trip Start Timestamp        Trip End Timestamp  Trip Seconds  \\\n",
              "0       2021-10-03 20:30:00+00:00 2021-10-03 21:00:00+00:00        1584.0   \n",
              "1       2021-10-03 20:30:00+00:00 2021-10-03 21:00:00+00:00        1606.0   \n",
              "2       2021-10-03 20:30:00+00:00 2021-10-03 20:45:00+00:00         660.0   \n",
              "3       2021-10-03 20:30:00+00:00 2021-10-03 20:30:00+00:00         498.0   \n",
              "4       2021-10-03 20:30:00+00:00 2021-10-03 20:45:00+00:00         618.0   \n",
              "...                           ...                       ...           ...   \n",
              "2618446 2021-01-01 20:45:00+00:00 2021-01-01 21:15:00+00:00        1500.0   \n",
              "2618447 2021-01-01 20:45:00+00:00 2021-01-01 21:00:00+00:00         807.0   \n",
              "2618448 2021-01-01 20:45:00+00:00 2021-01-01 21:00:00+00:00        1260.0   \n",
              "2618449 2021-01-01 20:45:00+00:00 2021-01-01 21:15:00+00:00        1320.0   \n",
              "2618450 2021-01-01 20:45:00+00:00 2021-01-01 21:15:00+00:00        1320.0   \n",
              "\n",
              "         Trip Miles  Pickup Centroid Latitude  Pickup Centroid Longitude  \n",
              "0             18.07                 41.877406                 -87.621972  \n",
              "1             16.60                 41.979071                 -87.903040  \n",
              "2              1.40                 41.899602                 -87.633308  \n",
              "3              3.45                 41.980264                 -87.913625  \n",
              "4              0.00                 41.878866                 -87.625192  \n",
              "...             ...                       ...                        ...  \n",
              "2618446       11.90                 41.707311                 -87.534903  \n",
              "2618447        4.21                 41.953582                 -87.723452  \n",
              "2618448        0.00                 41.792592                 -87.769615  \n",
              "2618449        8.90                 41.835118                 -87.618678  \n",
              "2618450       15.83                 41.899602                 -87.633308  \n",
              "\n",
              "[2410356 rows x 6 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "taxi_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NiVDTKaUrNDc"
      },
      "outputs": [],
      "source": [
        "# STEP 4: Clean and engineer features\n",
        "# ----------------------------------------\n",
        "# Filter out rows without spatial pickup info and compute trip metrics\n",
        "taxi_df = taxi_df.dropna(subset=[\"Pickup Centroid Latitude\", \"Pickup Centroid Longitude\"])\n",
        "taxi_df[\"trip_minutes\"] = taxi_df[\"Trip Seconds\"] / 60\n",
        "\n",
        "taxi_df[\"avg_speed_mph\"] = taxi_df[\"Trip Miles\"] / (taxi_df[\"trip_minutes\"] / 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W2r3quPjrVGR"
      },
      "outputs": [],
      "source": [
        "# Create geometry column for pickup locations\n",
        "taxi_df[\"geometry\"] = taxi_df.apply(lambda row: Point(row[\"Pickup Centroid Longitude\"], row[\"Pickup Centroid Latitude\"]), axis=1)\n",
        "gdf_taxi = gpd.GeoDataFrame(taxi_df, geometry=\"geometry\", crs=\"EPSG:4326\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "taxi_df.to_csv(\"cleaned_taxi_data.csv\", index=False)\n",
        "gdf_aq.to_csv(\"cleaned_air_quality_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cSYloyGvrgA3"
      },
      "outputs": [],
      "source": [
        "# METHOD A: SPATIAL JOIN USING BUFFER (Precise Proximity)\n",
        "# ----------------------------------------\n",
        "gdf_taxi_buffer = gdf_taxi.to_crs(epsg=3857)\n",
        "gdf_aq_buffer = gdf_aq.to_crs(epsg=3857)\n",
        "gdf_aq_buffer[\"geometry\"] = gdf_aq_buffer.buffer(200)  # 200m buffer around each sensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Qa1brOUtrgAL"
      },
      "outputs": [],
      "source": [
        "# Find taxi pickups within buffer zone of air sensors\n",
        "joined_buffer = gpd.sjoin(gdf_taxi_buffer, gdf_aq_buffer, how=\"inner\", predicate=\"within\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "joined_buffer.to_csv(\"spatial_join_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 23\n"
          ]
        }
      ],
      "source": [
        "def safe_merge_asof(left_df, right_df, on_left=\"Trip Start Timestamp\", on_right=\"ReadingDateTimeUTC\", batch_size=10000):\n",
        "    \"\"\"\n",
        "    Performs merge_asof in batches to avoid MemoryError.\n",
        "    \"\"\"\n",
        "    result_batches = []\n",
        "    right_sorted = right_df.sort_values(on_right)  # Sort right side once\n",
        "\n",
        "    for start in range(0, len(left_df), batch_size):\n",
        "        end = start + batch_size\n",
        "        batch = left_df.iloc[start:end].copy()\n",
        "\n",
        "        batch_sorted = batch.sort_values(on_left)\n",
        "\n",
        "        merged = pd.merge_asof(\n",
        "            batch_sorted,\n",
        "            right_sorted,\n",
        "            left_on=on_left,\n",
        "            right_on=on_right,\n",
        "            direction=\"nearest\",\n",
        "            tolerance=pd.Timedelta(\"15min\")\n",
        "        )\n",
        "        result_batches.append(merged)\n",
        "\n",
        "    print(\"✅ Batching merge completed.\")\n",
        "    return pd.concat(result_batches, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Local\\Temp\\ipykernel_21040\\2587913881.py\", line 3, in <module>\n",
            "    joined_buffer = safe_merge_asof(joined_buffer, gdf_aq_buffer)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Local\\Temp\\ipykernel_21040\\3966413573.py\", line 10, in safe_merge_asof\n",
            "    batch = left_df.iloc[start:end].copy()\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\geopandas\\geodataframe.py\", line 1826, in copy\n",
            "    copied = super().copy(deep=deep)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py\", line 6808, in copy\n",
            "    data = self._mgr.copy(deep=deep)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py\", line 604, in copy\n",
            "    res._consolidate_inplace()\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py\", line 1786, in _consolidate_inplace\n",
            "    self.blocks = _consolidate(self.blocks)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py\", line 2267, in _consolidate\n",
            "    merged_blocks, _ = _merge_blocks(\n",
            "                       ^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py\", line 2299, in _merge_blocks\n",
            "    new_values = new_values[argsort]\n",
            "                 ~~~~~~~~~~^^^^^^^^^\n",
            "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1016. KiB for an array with shape (13, 10000) and data type float64\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2176, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1053, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 861, in structured_traceback\n",
            "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 746, in format_exception_as_a_whole\n",
            "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
            "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
            "    yield from collapse_repeated(\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
            "    yield from map(mapper, original_group)\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
            "    return cls(f, options)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
            "    self.executing = Source.executing(frame_or_tb)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 264, in executing\n",
            "    source = cls.for_frame(frame)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
            "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
            "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
            "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
            "                                               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Abdullah\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 153, in __init__\n",
            "    self.text = ''.join(lines)\n",
            "                ^^^^^^^^^^^^^^\n",
            "MemoryError\n"
          ]
        }
      ],
      "source": [
        "gdf_aq_buffer = gdf_aq_buffer.sort_values(\"ReadingDateTimeUTC\")\n",
        "\n",
        "joined_buffer = safe_merge_asof(joined_buffer, gdf_aq_buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YG8-NYlyrovQ"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 9.71 GiB for an array with shape (6, 217297289) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Match each taxi pickup to closest-in-time sensor reading within 15 mins\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m joined_buffer = \u001b[43mjoined_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReadingDateTimeUTC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m joined_buffer = pd.merge_asof(\n\u001b[32m      4\u001b[39m     joined_buffer.sort_values(\u001b[33m\"\u001b[39m\u001b[33mTrip Start Timestamp\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     gdf_aq_buffer.sort_values(\u001b[33m\"\u001b[39m\u001b[33mReadingDateTimeUTC\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     tolerance=pd.Timedelta(\u001b[33m\"\u001b[39m\u001b[33m15min\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:7206\u001b[39m, in \u001b[36mDataFrame.sort_values\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7203\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7204\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m7206\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   7208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[32m   7211\u001b[39m     new_data.set_axis(\n\u001b[32m   7212\u001b[39m         \u001b[38;5;28mself\u001b[39m._get_block_manager_axis(axis), default_index(\u001b[38;5;28mlen\u001b[39m(indexer))\n\u001b[32m   7213\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     new_blocks = \u001b[43m[\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1304\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1306\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1314\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    155\u001b[39m     out = np.empty(out_shape, dtype=dtype, order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m func(arr, indexer, out, fill_value)\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 9.71 GiB for an array with shape (6, 217297289) and data type float64"
          ]
        }
      ],
      "source": [
        "# Match each taxi pickup to closest-in-time sensor reading within 15 mins\n",
        "joined_buffer = joined_buffer.sort_values(\"ReadingDateTimeUTC\")\n",
        "joined_buffer = pd.merge_asof(\n",
        "    joined_buffer.sort_values(\"Trip Start Timestamp\"),\n",
        "    gdf_aq_buffer.sort_values(\"ReadingDateTimeUTC\"),\n",
        "    left_on=\"Trip Start Timestamp\",\n",
        "    right_on=\"ReadingDateTimeUTC\",\n",
        "    direction=\"nearest\",\n",
        "    tolerance=pd.Timedelta(\"15min\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh2GEO05rux3"
      },
      "outputs": [],
      "source": [
        "# Aggregate by hour\n",
        "joined_buffer[\"hour\"] = joined_buffer[\"ReadingDateTimeUTC\"].dt.floor(\"H\")\n",
        "agg_buffer = joined_buffer.groupby(\"hour\").agg({\n",
        "    \"avg_speed_mph\": \"mean\",\n",
        "    \"trip_miles\": \"sum\",\n",
        "    \"trip_seconds\": \"count\",\n",
        "    \"CalibratedPM25\": \"mean\"\n",
        "}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q-S-vN44ryIf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'gdf_taxi' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# METHOD B: GEOHASH JOIN (Grid-based Fast Approximation)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Convert lat/lon to geohash codes\u001b[39;00m\n\u001b[32m      4\u001b[39m gdf_aq[\u001b[33m\"\u001b[39m\u001b[33mgeohash\u001b[39m\u001b[33m\"\u001b[39m] = gdf_aq.geometry.apply(\u001b[38;5;28;01mlambda\u001b[39;00m p: geohash2.encode(p.y, p.x, precision=\u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m gdf_taxi[\u001b[33m\"\u001b[39m\u001b[33mgeohash\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mgdf_taxi\u001b[49m.geometry.apply(\u001b[38;5;28;01mlambda\u001b[39;00m p: geohash2.encode(p.y, p.x, precision=\u001b[32m6\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'gdf_taxi' is not defined"
          ]
        }
      ],
      "source": [
        "# METHOD B: GEOHASH JOIN (Grid-based Fast Approximation)\n",
        "# ----------------------------------------\n",
        "# Convert lat/lon to geohash codes\n",
        "gdf_aq[\"geohash\"] = gdf_aq.geometry.apply(lambda p: geohash2.encode(p.y, p.x, precision=6))\n",
        "gdf_taxi[\"geohash\"] = gdf_taxi.geometry.apply(lambda p: geohash2.encode(p.y, p.x, precision=6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ6KB6Mqr1Kz"
      },
      "outputs": [],
      "source": [
        "# Join on geohash codes\n",
        "joined_hash = pd.merge(gdf_taxi, gdf_aq, on=\"geohash\", how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekReZEf_r3l_"
      },
      "outputs": [],
      "source": [
        "# Match nearest-in-time sensor reading\n",
        "joined_hash = joined_hash.sort_values(\"ReadingDateTimeUTC\")\n",
        "joined_hash = pd.merge_asof(\n",
        "    joined_hash.sort_values(\"trip_start_timestamp\"),\n",
        "    gdf_aq.sort_values(\"ReadingDateTimeUTC\"),\n",
        "    left_on=\"trip_start_timestamp\",\n",
        "    right_on=\"ReadingDateTimeUTC\",\n",
        "    direction=\"nearest\",\n",
        "    tolerance=pd.Timedelta(\"15min\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBdZE-dDr9m2"
      },
      "outputs": [],
      "source": [
        "# Aggregate by hour\n",
        "joined_hash[\"hour\"] = joined_hash[\"ReadingDateTimeUTC\"].dt.floor(\"H\")\n",
        "agg_hash = joined_hash.groupby(\"hour\").agg({\n",
        "    \"avg_speed_mph\": \"mean\",\n",
        "    \"trip_miles\": \"sum\",\n",
        "    \"trip_seconds\": \"count\",\n",
        "    \"CalibratedPM25\": \"mean\"\n",
        "}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEsdIa-gr-p-"
      },
      "outputs": [],
      "source": [
        "# COMPARISON VISUALIZATION\n",
        "# ----------------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(agg_buffer[\"hour\"], agg_buffer[\"CalibratedPM25\"], label=\"Buffer Method\")\n",
        "plt.plot(agg_hash[\"hour\"], agg_hash[\"CalibratedPM25\"], label=\"Geohash Method\")\n",
        "plt.title(\"PM2.5 Over Time: Buffer vs Geohash Join\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"PM2.5\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpW4-Q5HsB8p"
      },
      "outputs": [],
      "source": [
        "# SELECT AGGREGATION METHOD FOR DEEPER ANALYSIS\n",
        "# ----------------------------------------\n",
        "agg = agg_buffer.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsXV83t3sFLr"
      },
      "outputs": [],
      "source": [
        "# HISTOGRAMS\n",
        "# ----------------------------------------\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(agg[\"CalibratedPM25\"].dropna(), bins=20, edgecolor='black')\n",
        "plt.title(\"Histogram of Calibrated PM2.5\")\n",
        "plt.xlabel(\"PM2.5\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(agg[\"avg_speed_mph\"].dropna(), bins=20, edgecolor='black')\n",
        "plt.title(\"Histogram of Average Speed\")\n",
        "plt.xlabel(\"Speed (mph)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGUKxYASsIgr"
      },
      "outputs": [],
      "source": [
        "# SCATTERPLOTS WITH REGRESSION LINES\n",
        "# ----------------------------------------\n",
        "sns.lmplot(data=agg, x=\"avg_speed_mph\", y=\"CalibratedPM25\")\n",
        "plt.title(\"Speed vs PM2.5\\nFaster traffic is often associated with lower PM2.5 levels. Slower speeds may indicate congestion and poor air quality.\")\n",
        "plt.xlabel(\"Average Speed (mph)\")\n",
        "plt.ylabel(\"Calibrated PM2.5\")\n",
        "plt.show()\n",
        "\n",
        "sns.lmplot(data=agg, x=\"trip_seconds\", y=\"CalibratedPM25\")\n",
        "plt.title(\"Trip Count vs PM2.5\\nHigher trip counts can indicate increased congestion, possibly elevating air pollution levels.\")\n",
        "plt.xlabel(\"Trip Count\")\n",
        "plt.ylabel(\"Calibrated PM2.5\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fL3hjh_sLna"
      },
      "outputs": [],
      "source": [
        "# DBSCAN CLUSTERING\n",
        "# ----------------------------------------\n",
        "features = agg[[\"avg_speed_mph\", \"CalibratedPM25\"]].dropna()\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(features)\n",
        "db = DBSCAN(eps=0.5, min_samples=5).fit(scaled)\n",
        "agg[\"cluster\"] = -1\n",
        "agg.loc[features.index, \"cluster\"] = db.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7UVoPCesOOm"
      },
      "outputs": [],
      "source": [
        "# CLUSTER VISUALIZATION\n",
        "# ----------------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=agg, x=\"avg_speed_mph\", y=\"CalibratedPM25\", hue=\"cluster\", palette=\"tab10\")\n",
        "plt.title(\"DBSCAN Clusters: Speed vs PM2.5\\nClusters help identify patterns in traffic-air quality behavior (e.g., low speed + high PM2.5 = hotspots).\")\n",
        "plt.xlabel(\"Average Speed (mph)\")\n",
        "plt.ylabel(\"Calibrated PM2.5\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-_lMjjZsRB5"
      },
      "outputs": [],
      "source": [
        "# CORRELATION MATRIX\n",
        "# ----------------------------------------\n",
        "from datascience import Table as DTable\n",
        "final = DTable.from_df(agg)\n",
        "final.select(\"avg_speed_mph\", \"trip_miles\", \"trip_seconds\", \"CalibratedPM25\").corr()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
